---
# AI Code Review Role
# Performs comprehensive code review using AI agent

- name: Verify prerequisite context files exist
  stat:
    path: "{{ item }}"
  register: ai_code_review_prereq_files
  loop:
    - "{{ ai_code_review_context_output_file }}"
    - "{{ ai_code_review_commit_summary_file }}"
    - "{{ ai_code_review_style_guide_quick_rules }}"
    - "{{ ai_code_review_style_guide_comprehensive }}"

- name: Fail if prerequisite files missing
  fail:
    msg: "Missing prerequisite file: {{ item.item }}"
  when: not item.stat.exists
  loop: "{{ ai_code_review_prereq_files.results }}"

- name: Create code review prompt with @file references and subagent invocation
  set_fact:
    ai_code_review_review_prompt: >-
      Use the @agent-code-review-agent subagent to
      perform a comprehensive code review of the change.

      Read @{{ ai_code_review_context_output_file }} for Zuul execution context.
      Read @{{ ai_code_review_commit_summary_file }} for commit metadata and change summary.
      Read @{{ ai_code_review_style_guide_quick_rules }} for essential OpenStack coding standards and rules.
      Read @{{ ai_code_review_style_guide_comprehensive }} for detailed explanations and complex scenarios.

      The project under review is located at: {{ ai_code_review_project_src_dir }}

      Generate a structured JSON review report conforming to the review-report schema
      with severity-categorized findings (critical, high, warnings, suggestions) and write it to
      {{ ai_code_review_report_file }}

- name: Execute code review with Claude
  include_tasks: "../../ai_review_setup/tasks/run-claude-command.yaml"
  vars:
    prompt_text: "{{ ai_code_review_review_prompt }}"
    model_name: "{{ ai_code_review_model }}"
    output_file: "{{ ai_code_review_report_file }}"
    command_name: "code review"
    working_dir: "{{ ai_code_review_project_src_dir }}"

- name: Extract issue statistics from JSON report
  shell: |
    jq -r '.statistics | "Critical: \(.critical), High: \(.high), Warnings: \(.warnings), Suggestions: \(.suggestions), Total: \(.total)"' \
      "{{ ai_code_review_report_file }}"
  register: ai_code_review_issue_statistics
  changed_when: false

- name: Get total issue count from JSON
  shell: |
    jq -r '.statistics.total' "{{ ai_code_review_report_file }}"
  register: ai_code_review_issue_count_result
  changed_when: false

- name: Get critical + high issue count from JSON
  shell: |
    jq -r '(.statistics.critical + .statistics.high)' "{{ ai_code_review_report_file }}"
  register: ai_code_review_critical_high_count
  changed_when: false

- name: Set review result facts
  set_fact:
    ai_code_review_issue_count: "{{ ai_code_review_issue_count_result.stdout | int }}"
    ai_code_review_critical_high_issues: "{{ ai_code_review_critical_high_count.stdout | int }}"
    ai_code_review_has_issues: "{{ ai_code_review_issue_count_result.stdout | int > 0 }}"
    ai_code_review_has_critical_issues: "{{ ai_code_review_critical_high_count.stdout | int > 0 }}"
    ai_code_review_issue_statistics: "{{ ai_code_review_issue_statistics }}"

- name: Display review summary
  debug:
    msg: |
      Review Summary:
      {{ ai_code_review_issue_statistics.stdout }}
      Status: {{ 'NEEDS ATTENTION' if ai_code_review_has_critical_issues else ('HAS SUGGESTIONS' if ai_code_review_has_issues else 'CLEAN') }}
